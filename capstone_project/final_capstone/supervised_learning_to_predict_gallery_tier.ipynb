{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration to Predict Gallery Tier\n",
    "### First step towards building an objective Gallery Qualification Score\n",
    "**Author: Nicholas Sewitz  \n",
    "Contributors: Anil Bawa-Cavia, Will Goldstein**\n",
    "\n",
    "This notebook processes certain predetermined features that we believe are predictive of the qualitative gallery tier score applied by the GFI team. The goal is to identify what features and models should be used to build a more ambitious objective qualification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import datetime\n",
    "sys.path.append(os.environ['minotaur'])\n",
    "\n",
    "import os.path\n",
    "import http\n",
    "import urllib.request \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from socket import timeout\n",
    "import boto3\n",
    "import gzip\n",
    "import io\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "\n",
    "import yaml\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14,3\n",
    "\n",
    "from dbs import redshift\n",
    "redshift.connect()\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "from pygeocoder import Geocoder\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "from slugify import slugify\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, scale\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Wrangling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ./data_wrangling_to_predict_qualification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO # Python 2.x\n",
    "else:\n",
    "    from io import StringIO # Python 3.x\n",
    "\n",
    "# get your credentials from environment variables\n",
    "aws_id = os.environ['AWS_ID']\n",
    "aws_secret = os.environ['AWS_SECRET']\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_id,\n",
    "        aws_secret_access_key=aws_secret)\n",
    "\n",
    "bucket_name = 'artsy-data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_key = 'temp/df_with_less_text.csv'\n",
    "csv_obj = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "\n",
    "df_with_less_text = pd.read_csv(StringIO(csv_string))\n",
    "del df_with_less_text['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_key = 'temp/df_with_many_text.csv'\n",
    "csv_obj = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "\n",
    "df_with_many_text = pd.read_csv(StringIO(csv_string))\n",
    "del df_with_many_text['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Learning for Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Stemming performed worse\n",
    "\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# potentially look at this regionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "# # for df in df_with_many_features, df_with_many_text_not_on_artsy:    \n",
    "# #     texts = [[c for c in df.columns if c == 'stemmed'],\n",
    "# #              [c for c in df.columns if c == 'text_parse']]\n",
    "             \n",
    "# #     for text in texts:        \n",
    "# #         X = df[text]\n",
    "\n",
    "\n",
    "\n",
    "# # Define a pipeline combining a text feature extractor with a simple\n",
    "# # classifier\n",
    "# pipeline = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', LogisticRegression(class_weight='balanced')),\n",
    "#     #('log', LogisticRegression()),\n",
    "# ])\n",
    "\n",
    "# # uncommenting more parameters will give better exploring power but will\n",
    "# # increase processing time in a combinatorial way\n",
    "# parameters = {        \n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#     #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "#     #'tfidf__use_idf': (True, False),\n",
    "#     #'tfidf__norm': ('l1', 'l2'),\n",
    "#     'clf__alpha': (0.00001, 0.000001),\n",
    "#     'clf__penalty': ('l2', 'elasticnet'),\n",
    "#     'clf__n_iter': (10, 50, 80),\n",
    "# #     'log__C': np.logspace(-5, 8, 15, 50, 100), \n",
    "# #      'log__penalty': ['l1', 'l2'],\n",
    "# #      'log__class_weight': ['balanced']\n",
    "# }\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # multiprocessing requires the fork to happen in a __main__ protected\n",
    "#     # block\n",
    "\n",
    "#     # find the best parameters for both the feature extraction and the\n",
    "#     # classifier\n",
    "#     #grid_search = GridSearchCV(pipeline, parameters)\n",
    "\n",
    "#     print(\"Performing grid search...\")\n",
    "#     print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "#     print(\"parameters:\")\n",
    "#     pprint(parameters)\n",
    "#     t0 = time()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df_open_with_less_text.text_parse, df_open_with_less_text.gallery_tier, test_size=0.3, random_state=42)\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     print(\"done in %0.3fs\" % (time() - t0))\n",
    "#     print()\n",
    "\n",
    "\n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# #     print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# #     print(\"Best parameters set:\")\n",
    "# #     best_parameters = grid_search.best_estimator_.get_params()\n",
    "# #     for param_name in sorted(parameters.keys()):\n",
    "# #         print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "#     print(\"Classification report for classifier %s:\\n\"\n",
    "#       % classification_report(y_test, y_pred))\n",
    "#     print(\"Confusion Matrix for classifier %s:\\n\"\n",
    "#       % confusion_matrix(y_test, y_pred))   \n",
    "#     #df_with_less_text['text_log_results'] = grid_search.predict(df_with_less_text.text_parse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Classification Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>gallery_tier</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>inquiry_requests_count</th>\n",
       "      <th>bid_count</th>\n",
       "      <th>on_artsy</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>artist_slug</th>\n",
       "      <th>min_distance_to_art_city</th>\n",
       "      <th>disqualified_reason</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>partner_on_artsy</th>\n",
       "      <th>text_parse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualified</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_qualified</th>\n",
       "      <td>3180</td>\n",
       "      <td>3181</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>295</td>\n",
       "      <td>295</td>\n",
       "      <td>804</td>\n",
       "      <td>349</td>\n",
       "      <td>804</td>\n",
       "      <td>718</td>\n",
       "      <td>3181</td>\n",
       "      <td>3181</td>\n",
       "      <td>3181</td>\n",
       "      <td>2567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualified</th>\n",
       "      <td>97283</td>\n",
       "      <td>97283</td>\n",
       "      <td>1711</td>\n",
       "      <td>1711</td>\n",
       "      <td>2852</td>\n",
       "      <td>2852</td>\n",
       "      <td>5430</td>\n",
       "      <td>3373</td>\n",
       "      <td>5430</td>\n",
       "      <td>29621</td>\n",
       "      <td>97283</td>\n",
       "      <td>97283</td>\n",
       "      <td>97283</td>\n",
       "      <td>95293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very_qualified</th>\n",
       "      <td>1652</td>\n",
       "      <td>1652</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>1130</td>\n",
       "      <td>1130</td>\n",
       "      <td>1291</td>\n",
       "      <td>1149</td>\n",
       "      <td>1291</td>\n",
       "      <td>863</td>\n",
       "      <td>1652</td>\n",
       "      <td>1652</td>\n",
       "      <td>1652</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                domain  gallery_tier  Clicks  Impressions  \\\n",
       "qualified                                                   \n",
       "not_qualified     3180          3181     172          172   \n",
       "qualified        97283         97283    1711         1711   \n",
       "very_qualified    1652          1652     888          888   \n",
       "\n",
       "                inquiry_requests_count  bid_count  on_artsy  search_volume  \\\n",
       "qualified                                                                    \n",
       "not_qualified                      295        295       804            349   \n",
       "qualified                         2852       2852      5430           3373   \n",
       "very_qualified                    1130       1130      1291           1149   \n",
       "\n",
       "                artist_slug  min_distance_to_art_city  disqualified_reason  \\\n",
       "qualified                                                                    \n",
       "not_qualified           804                       718                 3181   \n",
       "qualified              5430                     29621                97283   \n",
       "very_qualified         1291                       863                 1652   \n",
       "\n",
       "                is_closed  partner_on_artsy  text_parse  \n",
       "qualified                                                \n",
       "not_qualified        3181              3181        2567  \n",
       "qualified           97283             97283       95293  \n",
       "very_qualified       1652              1652        1493  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_less_text.groupby('qualified').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123, 5)\n",
      "(3123, 5)\n"
     ]
    }
   ],
   "source": [
    "# remove most artists features because they are strongly correlated and have low coverage\n",
    "\n",
    "X = df_with_less_text.copy()\n",
    "del X['gallery_tier']\n",
    "del X['domain']\n",
    "del X['Clicks']\n",
    "del X['disqualified_reason']\n",
    "del X['is_closed']\n",
    "del X['bid_count']\n",
    "del X['inquiry_requests_count']\n",
    "del X['Impressions']\n",
    "del X['text_parse']\n",
    "#del X['stemmed']\n",
    "del X['partner_on_artsy']\n",
    "\n",
    "str_cols = ['on_artsy','search_volume']\n",
    "X[str_cols] = X[str_cols].fillna(0)\n",
    "X = X.dropna()\n",
    "X.reset_index(inplace=True,drop=True)\n",
    "print(X.shape)\n",
    "#X = X[(X.qualified == 'not_qualified') | (X.qualified == 'very_qualified')]\n",
    "y = X.qualified\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>on_artsy</th>\n",
       "      <th>search_volume</th>\n",
       "      <th>artist_slug</th>\n",
       "      <th>min_distance_to_art_city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualified</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_qualified</th>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualified</th>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very_qualified</th>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                on_artsy  search_volume  artist_slug  min_distance_to_art_city\n",
       "qualified                                                                     \n",
       "not_qualified        262            262          262                       262\n",
       "qualified           2115           2115         2115                      2115\n",
       "very_qualified       746            746          746                       746"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.groupby('qualified').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X['qualified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Scaling: 0.6894343649946638\n",
      "Accuracy without Scaling: 0.7001067235859125\n"
     ]
    }
   ],
   "source": [
    "# Setup the pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('dec', LogisticRegression())]\n",
    "        \n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the training set: knn_scaled\n",
    "log_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Instantiate and fit a Log classifier to the unscaled data\n",
    "log_unscaled = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print('Accuracy with Scaling: {}'.format(log_scaled.score(X_test, y_test)))\n",
    "print('Accuracy without Scaling: {}'.format(log_unscaled.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.19306977288832536, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "0.711846318036\n",
      "0.271077908218\n",
      "Classification report for classifier                 precision    recall  f1-score   support\n",
      "\n",
      " not_qualified       0.12      0.49      0.19        72\n",
      "     qualified       0.00      0.00      0.00       623\n",
      "very_qualified       0.34      0.90      0.49       242\n",
      "\n",
      "   avg / total       0.10      0.27      0.14       937\n",
      ":\n",
      "\n",
      "Confusion Matrix for classifier [[ 35   0  37]\n",
      " [229   0 394]\n",
      " [ 23   0 219]]:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15, 50, 100)\n",
    "\n",
    "param_grid = {'C': c_space, \n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'class_weight': ['balanced']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.3,random_state=42)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg,param_grid,cv=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "############\n",
    "\n",
    "print(logreg_cv.best_params_)\n",
    "print(logreg_cv.score(X_test, y_test))\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced',penalty='l1', C=5.1794746792312125e-07)\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "############\n",
    "\n",
    "print(logreg.score(X_test, y_test))\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n\"\n",
    "      % classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix for classifier %s:\\n\"\n",
    "      % confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # won't work right now for multi-class classifier\n",
    "\n",
    "# # Import necessary modules\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# # Compute predicted probabilities: y_pred_prob\n",
    "# y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# # Generate ROC curve values: fpr, tpr, thresholds\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# # Plot ROC curve\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAADQCAYAAACUYku5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJUgf8f6bO1XY56ze4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ec325c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = abs(logreg.coef_[0])\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "\n",
    "featfig = plt.figure()\n",
    "featax = featfig.add_subplot(1, 1, 1)\n",
    "featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "featax.set_yticks(pos)\n",
    "featax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\n",
    "featax.set_xlabel('Relative Feature Importance')\n",
    "\n",
    "plt.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regression Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Scaling: 0.7986798679867987\n",
      "Accuracy without Scaling: 0.8085808580858086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Setup the pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('dec', DecisionTreeClassifier())]\n",
    "        \n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the training set: dec_scaled\n",
    "dec_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Instantiate and fit a Decision Tree classifier to the unscaled data\n",
    "dec_unscaled = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print('Accuracy with Scaling: {}'.format(dec_scaled.score(X_test, y_test)))\n",
    "print('Accuracy without Scaling: {}'.format(dec_unscaled.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 1, 'min_samples_leaf': 4}\n",
      "0.819858156028\n",
      "Classification report for classifier                 precision    recall  f1-score   support\n",
      "\n",
      " not_qualified       0.53      0.66      0.59        76\n",
      "very_qualified       0.88      0.81      0.84       227\n",
      "\n",
      "   avg / total       0.79      0.77      0.78       303\n",
      ":\n",
      "\n",
      "Confusion Matrix for classifier [[ 50  26]\n",
      " [ 44 183]]:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "param_dist = {\"max_depth\": [3,5,10,20,50,100],\n",
    "              \"max_features\": [1,3,4],\n",
    "              \"min_samples_leaf\": [1,3,4],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"class_weight\": [\"balanced\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = GridSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train, y_train)    \n",
    "\n",
    "y_pred = tree_cv.predict(X_test)\n",
    "\n",
    "print(tree_cv.best_params_)\n",
    "print(tree_cv.best_score_)\n",
    "print(\"Classification report for classifier %s:\\n\"\n",
    "      % classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix for classifier %s:\\n\"\n",
    "      % confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.43      0.49        65\n",
      "        100       0.50      0.64      0.56        58\n",
      "\n",
      "avg / total       0.54      0.53      0.52       123\n",
      ":\n",
      "\n",
      "Confusion Matrix for classifier [[28 37]\n",
      " [21 37]]:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier(class_weight= 'balanced', criterion= 'gini', max_depth= 3, max_features= 7, min_samples_leaf= 3)\n",
    "\n",
    "# Fit it to the data\n",
    "tree.fit(X_train, y_train)    \n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n\"\n",
    "      % classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix for classifier %s:\\n\"\n",
    "      % confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100, 'n_jobs': -1}\n",
      "0.85390070922\n",
      "Classification report for classifier                 precision    recall  f1-score   support\n",
      "\n",
      " not_qualified       0.59      0.71      0.65        76\n",
      "very_qualified       0.90      0.84      0.87       227\n",
      "\n",
      "   avg / total       0.82      0.81      0.81       303\n",
      ":\n",
      "\n",
      "Confusion Matrix for classifier [[ 54  22]\n",
      " [ 37 190]]:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "param_dist = {\"n_estimators\": [1,5,10,100,200],\n",
    "              \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "              \"max_depth\": [1,5,10,50,100],\n",
    "              \"n_jobs\": [-1,1,5,10],\n",
    "              \"class_weight\": [\"balanced\"] }\n",
    "\n",
    "# Instantiate a Random Forest classifier: tree\n",
    "forest = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "forest_cv = GridSearchCV(forest, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest_cv.predict(X_test)\n",
    "\n",
    "print(forest_cv.best_params_)\n",
    "print(forest_cv.best_score_)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n\"\n",
    "      % classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix for classifier %s:\\n\"\n",
    "      % confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non CV Forest\n",
      "Classification report for classifier              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.43      0.49        65\n",
      "        100       0.50      0.64      0.56        58\n",
      "\n",
      "avg / total       0.54      0.53      0.52       123\n",
      ":\n",
      "\n",
      "Confusion Matrix for classifier [[28 37]\n",
      " [21 37]]:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "forest = RandomForestClassifier(class_weight='balanced', max_depth= 5, max_features= 'auto', n_estimators= 200, n_jobs= 1)\n",
    "\n",
    "# Fit it to the data\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "#can change to predict_proba to get the probabilities\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "print(\"Non CV Forest\")\n",
    "print(\"Classification report for classifier %s:\\n\"\n",
    "      % classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix for classifier %s:\\n\"\n",
    "      % confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA68AAADgCAYAAADsflDNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1148f9748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest.fit(X,y)\n",
    "\n",
    "imp = forest.feature_importances_\n",
    "names = X.columns\n",
    "\n",
    "imp, names = zip(*sorted(zip(imp,names)))\n",
    "\n",
    "plt.barh(range(len(names)), imp, align = 'center')\n",
    "plt.yticks(range(len(names)), names)\n",
    "\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Importance of each Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://bigdata-madesimple.com/dealing-with-unbalanced-class-svm-random-forest-and-decision-tree-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_open_with_many_text_not_on_artsy_undersample = pd.concat([df_open_with_many_text_not_on_artsy[df_open_with_many_text_not_on_artsy.gallery_tier == 0],\n",
    "                                                             df_open_with_many_text_not_on_artsy[df_open_with_many_text_not_on_artsy.gallery_tier == 100].head(204)])\n",
    "\n",
    "df_open_with_many_features_undersample = pd.concat([df_open_with_many_features[df_open_with_many_features.gallery_tier == 0], \n",
    "                                                    df_open_with_many_features[df_open_with_many_features.gallery_tier == 100].head(240)])df_open_with_many_text_not_on_artsy_undersample = pd.concat([df_open_with_many_text_not_on_artsy[df_open_with_many_text_not_on_artsy.gallery_tier == 0],\n",
    "                                                             df_open_with_many_text_not_on_artsy[df_open_with_many_text_not_on_artsy.gallery_tier == 100].head(204)])\n",
    "\n",
    "df_open_with_many_features_undersample = pd.concat([df_open_with_many_features[df_open_with_many_features.gallery_tier == 0], \n",
    "                                                    df_open_with_many_features[df_open_with_many_features.gallery_tier == 100].head(240)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: Artists on Artsy, Artists Inquiries, Artists Bids, Fairs Participated In, Location, Google Search Score for Artist Name \n",
    "Optional: Structured data from website scrape (looking for keywords such Fair, Artists, Exhibitions, Current Exhibition, Past Exhibitions, Represented, Works Available, Services (negative), Submissions (negative) ) \n",
    "\n",
    "Take a list of orgs in bearden that have been tiered and have scraped artists. Score those galleries both computationally and by hand, and compare.\n",
    "\n",
    "Another potential todo: Score a group of artsy partners, observe the distribution of scores-- giving a us a cutoff.\n",
    "\n",
    "Final step, score the whole list of scraped artist galleries in bearden and see how much of distribution falls above cutoff giving a sense of TAM.\n",
    "\n",
    "Heuristic models, combine linearly, set coefficients. once have heuristic model can compare to other models\n",
    "eg. inquiries more important than fairs by 5x\n",
    "still need pos and neg\n",
    "\n",
    "will have to deal with biased positives\n",
    "could normalize by amount of time been on the platform\n",
    "\n",
    "pos = sub with artist roster\n",
    "neg = tier 5 with artist roster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: Artists on Artsy, Artists Inquiries, Artists Bids, Fairs Participated In, Location, Google Search Score for Artist Name \n",
    "Optional: Structured data from website scrape (looking for keywords such Fair, Artists, Exhibitions, Current Exhibition, Past Exhibitions, Represented, Works Available, Services (negative), Submissions (negative) ) \n",
    "\n",
    "Other information from website beyond keywords: don't even know \n",
    "\n",
    "---------\n",
    "\n",
    "artists_table = on_artsy, artist_inquries_count, artist_bid_count, google_search_score  \n",
    "org_table = website, bearden_id, partner_id, location  \n",
    "org_fairs = website, fair_name, fair_tier  \n",
    "\n",
    "---------\n",
    "\n",
    "Take a list of orgs in bearden that have been tiered and have scraped artists. Score those galleries both computationally and by hand, and compare.\n",
    "\n",
    "Another potential todo: Score a group of artsy partners, observe the distribution of scores-- giving a us a cutoff.\n",
    "\n",
    "Final step, score the whole list of scraped artist galleries in bearden and see how much of distribution falls above cutoff giving a sense of TAM.\n",
    "\n",
    "---------\n",
    "\n",
    "Could be interesting to look at galleries that we have only tier but not artist roster.\n",
    "\n",
    "---------\n",
    "\n",
    "if you have thousands of human scored galleries\n",
    "you might want to see how many of those have, say, three or more of the features you're looking to use.\n",
    "\n",
    "if you have a few hundred or more you could do a logistic regression on those scores\n",
    "like that you don't have to worry about classes, positives or negatives, as long as you have a good range of scores in there.\n",
    "\n",
    "that regression will give you a basic sense of the importance of each of those features in determining the score\n",
    "as you can reason about the model by just looking at the coefficients it outputs for each feature\n",
    "\n",
    "it would be good to try and leverage those scores if we have some faith in their consistency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**notes from meeting 11/30**\n",
    "\n",
    "- *Decision Tree to small, Change to RandomForest Classifier*\n",
    "- Normalize for how long artist has been on the platform maybe?\n",
    "- *pass in class weights for logreg*\n",
    "- *translate tier into #'s*\n",
    "- *redundency between Impressions and Search Volume, remove one*\n",
    "- include target in correlation and scatter matrix (new type of matrix)\n",
    "    - Pair wise plots\n",
    "- *Use either region or distance from art center *\n",
    "- Look into how well artist slug match works, otherwise use Artsy Artist Name Match API\n",
    "- Too much class imbalance\n",
    "    - ie only predicting certain tiers\n",
    "    - class weights might help\n",
    "        - not all tiers are equal\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
